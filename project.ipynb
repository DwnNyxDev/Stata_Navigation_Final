{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd85814d",
   "metadata": {},
   "source": [
    "# Stata Navigation Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a7216e",
   "metadata": {},
   "source": [
    "## Project Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385a616e",
   "metadata": {},
   "source": [
    "* [Load and Test Pretrained Places365 Model](#load-and-test-pretrained-places365-model)\n",
    "* Load and Process Images of Stata\n",
    "* Retrain Places365 Model\n",
    "* Test Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d710ef",
   "metadata": {},
   "source": [
    "## Load and Test Pretrained Places365 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdbc1ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b780040d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 predicted places:\n",
      "bar (0.7915)\n",
      "pharmacy (0.1112)\n",
      "beer_hall (0.0362)\n",
      "sushi_bar (0.0170)\n",
      "drugstore (0.0123)\n"
     ]
    }
   ],
   "source": [
    "#Load previously trained places365 model\n",
    "model = models.resnet50(num_classes=365)\n",
    "model_file = 'resnet50_places365.pth.tar'\n",
    "checkpoint = torch.load(model_file, map_location='cpu')\n",
    "state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Check if a gpu is available and move the model to the appropriate device\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to('cuda')\n",
    "else:\n",
    "    model = model.to('cpu')\n",
    "\n",
    "\n",
    "# Define an image preprocessing function\n",
    "# The model expects images of size 224x224 and normalized with ImageNet statistics\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],  # ImageNet means\n",
    "        std=[0.229, 0.224, 0.225]    # ImageNet stds\n",
    "    )\n",
    "])\n",
    "\n",
    "# Load the class labels\n",
    "file_name = 'categories_places365.txt'\n",
    "classes = list()\n",
    "with open(file_name) as class_file:\n",
    "    for line in class_file:\n",
    "        classes.append(line.strip().split(' ')[0][3:])\n",
    "classes = tuple(classes)\n",
    "\n",
    "\n",
    "# Load an image from a URL image address\n",
    "image_url = 'https://images.unsplash.com/photo-1597290282695-edc43d0e7129?fm=jpg&q=60&w=3000&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxzZWFyY2h8NHx8YmFyfGVufDB8fDB8fHww'  # replace with your image URL\n",
    "img = Image.open(urllib.request.urlopen(image_url)).convert('RGB')\n",
    "\n",
    "# Preprocess the image\n",
    "input_img = transform(img).unsqueeze(0)  # add batch dimension\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    logits = model(input_img)\n",
    "    probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "\n",
    "# Get the top-5 predictions\n",
    "top5_probs, top5_idxs = probs.topk(5)\n",
    "\n",
    "print(\"Top 5 predicted places:\")\n",
    "for prob, idx in zip(top5_probs[0], top5_idxs[0]):\n",
    "    print(f\"{classes[idx.item()]} ({prob.item():.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
